name: builds
description: "CI workflow for Olive"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  workflow_dispatch:
  push:
    branches:
      - main
      - rel-*
    paths:
      - '**'
      - '!docs/*'
      - '!examples/README.md'
      - '!examples/**/README.md'
      - '!README.md'
      - '!CONTRIBUTING.md'
      - '!LICENSE'
      # commonly updated examples with no test
      - '!examples/deepseek/**'
      - '!examples/directml/llm/**'
      - '!examples/directml/stable_diffusion_xl/**'
      - '!examples/llama2/**'
      - '!examples/llama3/**'
      - '!examples/mistral/**'
      - '!examples/open_llama/**'
      - '!examples/phi2/**'
      - '!examples/phi3/**'
      - '!examples/phi3_5/**'
      - '!examples/qwen2_5/**'
  pull_request:
    paths:
      - '**'
      - '!docs/*'
      - '!examples/README.md'
      - '!examples/**/README.md'
      - '!README.md'
      - '!CONTRIBUTING.md'
      - '!LICENSE'
      # commonly updated examples with no test
      - '!examples/deepseek/**'
      - '!examples/directml/llm/**'
      - '!examples/directml/stable_diffusion_xl/**'
      - '!examples/llama2/**'
      - '!examples/llama3/**'
      - '!examples/mistral/**'
      - '!examples/open_llama/**'
      - '!examples/phi2/**'
      - '!examples/phi3/**'
      - '!examples/phi3_5/**'
      - '!examples/qwen2_5/**'

env:
  PYTHON_VERSION: "3.10"
  TENSORRT_VERSION: "10.5.0.18-1+cuda12.6"
  PYTORCH_PACKAGE_NAME: "torch"
  ONNXRUNTIME_PACKAGE_NAME: "onnxruntime"

  HF_HOME: ${{ github.workspace }}/.cache/huggingface
  HUGGING_FACE_HUB_TOKEN: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}

  WORKSPACE_NAME: ${{ secrets.AZURE_WORKSPACE_NAME }}
  WORKSPACE_SUBSCRIPTION_ID: ${{ secrets.AZURE_WORKSPACE_SUBSCRIPTION_ID }}
  WORKSPACE_RESOURCE_GROUP: ${{ secrets.AZURE_WORKSPACE_RESOURCE_GROUP }}
  MANAGED_IDENTITY_CLIENT_ID: ${{ secrets.AZURE_MANAGED_IDENTITY_CLIENT_ID }}
  EXCLUDE_MANAGED_IDENTITY_CREDENTIAL: ${{ secrets.AZURE_EXCLUDE_MANAGED_IDENTITY_CREDENTIAL }}
  AZURE_KEY_VAULT: ${{ secrets.AZURE_KEY_VAULT }}

  DOCKER_FILEPATH: "./.azure_pipelines/dockerfiles/linux-gpu.dockerfile"
  DOCKER_IMAGE_NAME: "olive-pipeline:latest"
  DOCKER_BASE_IMAGE_NAME: "mcr.microsoft.com/mirror/nvcr/nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04"

  LINUX_CPU_POOL: "olive-1es-pool-ubuntu2004"
  LINUX_GPU_POOL: "olive-1es-pool-ubuntu2004-gpu-v100-eastus"
  WINDOWS_CPU_POOL: "olive-1es-pool-win2019"

jobs:
  cpu-test:
    strategy:
      fail-fast: false
      matrix:
        runs-on:
        - { os: "ubuntu-latest", shell: "bash" }
        - { os: "windows-latest", shell: "cmd" }
        device: ["cpu"]
        test-type: ["unit_test", "integ_test", "multiple_ep"]

    name: ${{ matrix.runs-on.os }} | ${{ matrix.test-type }} | ${{ matrix.device }}
    runs-on: ${{ matrix.runs-on.os }}

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4

    - name: Run Test
      uses: ./.github/actions/cpu-test
      with:
        shell: ${{ matrix.runs-on.shell }}
        python_version: ${{ env.PYTHON_VERSION }}
        test-type: ${{ matrix.test-type }}
        onnxruntime: ${{ env.ONNXRUNTIME_PACKAGE_NAME }}
        torch: ${{ env.PYTORCH_PACKAGE_NAME }}


  gpu-test:
    strategy:
      fail-fast: false
      matrix:
        runs-on:
        # - { os: "ubuntu-latest", shell: "bash" }
        - { os: "olive-1es-pool-ubuntu2004-gpu-v100-eastus", shell: "bash" }
        device: ["gpu"]
        test-type: ["unit_test"]

    name: ${{ matrix.runs-on.os }} | ${{ matrix.test-type }} | ${{ matrix.device }}
    runs-on: ${{ matrix.runs-on.os }}
    if: false
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4

    - name: Run Test
      uses: ./.github/actions/gpu-test
      with:
        shell: ${{ matrix.runs-on.shell }}
        python_version: ${{ env.PYTHON_VERSION }}
        test-type: ${{ matrix.test-type }}
        onnxruntime: ${{ env.ONNXRUNTIME_PACKAGE_NAME }}
        torch: ${{ env.PYTORCH_PACKAGE_NAME }}


  build-docs:
    name: Build Docs
    runs-on: "ubuntu-latest"

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4

    - name: Run Setup
      uses: ./.github/actions/setup
      with:
        shell: bash
        python_version: "3.9"
        onnxruntime: ${{ env.ONNXRUNTIME_PACKAGE_NAME }}
        torch: ${{ env.PYTORCH_PACKAGE_NAME }}
        hf_cache_key: ''
        requirements_file: "docs/requirements.txt"

    - name: Build Docs
      working-directory: ${{ github.workspace }}/docs
      run: |
        make html
        make linkcheck
        make schema


  examples:
    strategy:
      fail-fast: false
      matrix:
        runs-on:
        - { os: "ubuntu-latest", shell: "bash" }
        - { os: "windows-latest", shell: "cmd" }
        device: ["cpu"]
        example:
        - { name: "bert_ptq_cpu", model: "bert", folder: "examples/bert" }
        - { name: "resnet_ptq_cpu", model: "resnet", folder: "examples/resnet" }
        - { name: "whisper", model: "whisper", folder: "examples/whisper" }
        - { name: "mobilenet_qnn_ep", model: "mobilenet", folder: "examples/mobilenet/qnn" }

    name: ${{ matrix.runs-on.os }} | ${{ matrix.example.name }} | ${{ matrix.device }}
    runs-on: ${{ matrix.runs-on.os }}

    steps:
    - name: Checkout Code
      uses: actions/checkout@v4

    - name: Discover requirements file
      shell: bash
      working-directory: ${{ github.workspace }}/${{ matrix.example.folder }}
      run: |
        echo PWD=$PWD
        requirements_file=requirements.txt
        requirements_file_cpu=requirements_cpu.txt
        requirements_file_gpu=requirements_gpu.txt

        if [ -f "${requirements_file_cpu}" ]; then
          echo "requirements_file=${requirements_file_cpu}" >> $GITHUB_ENV
        elif [ -f "${requirements_file_gpu}" ]; then
          echo "requirements_file=${requirements_file_gpu}" >> $GITHUB_ENV
        elif [ -f "${requirements_file}" ]; then
          echo "requirements_file=${requirements_file}" >> $GITHUB_ENV
        fi

    - name: Run Setup
      uses: ./.github/actions/setup
      with:
        shell: ${{ matrix.runs-on.shell }}
        python_version: ${{ env.PYTHON_VERSION }}
        onnxruntime: ${{ env.ONNXRUNTIME_PACKAGE_NAME }}
        torch: ${{ env.PYTORCH_PACKAGE_NAME }}
        hf_cache_key: ${{ matrix.runs-on.os }}-${{ matrix.example.model }}-hf-cache
        requirements_file: ${{ matrix.example.folder }}/${{ env.requirements_file }}

    - name: Run Example Test
      env:
        PYTEST_BASETEMP: ${{ github.workspace }}/.pytest_basetemp
      run: |
        echo "Using requirements file: ${{ env.requirements_file }}"
        python -m pip install pytest azure-identity azure-storage-blob tabulate
        python -m pytest -v -s --log-cli-level=WARNING --junitxml=${{ github.workspace }}/logs/test_examples-TestOlive.xml ${{ github.workspace }}/examples/test/local/test_${{ matrix.example.name }}.py --basetemp ${{ env.PYTEST_BASETEMP }}
